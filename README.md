# Filtro_Anti-Hater_per_Social_Network
This repository is the seventh project of my master in Data Science

Questo progetto si trova a conclusione del modulo “Deep Learning e reti neurali artificiali". Gli argomenti affrontati sono: basi di rete neurali artificiali, addestramento e metodi di ottimizzazione, reti neurali convenzionali, reti neurali ricorrenti, architetture di reti neurali miste e transformes.

Il progetto richiede la realizzazione di un filtro anti-hater per social network. La richiesta richiede di associare ad ogni commento una o più delle seguenti etichette: tossico, severamente tossico, osceno, minaccioso, insulto, messaggio di odio. Questo progetto presenta 3 nuove sfide: lavorare con la classificazione di testi, classificazione multi-label e utilizzo di reti neurali, in paticolare la richiesta è di usare un'architettura a laser ricorrenti, scelta naturale quando dobbiamo creare modelli per classificare testi. I layer ricorrenti possono tenere "memoria" delle informazioni semanticamente importanti delle parole già analizzate agli step precedenti.

Le fasi di questo progetto sono state:
1. Analisi esplorativa dei dati: nell'analisi esplorativa mi sono posto 3 domande principali: come è distribuita ogni categoria di tossicità? Quanti commenti hanno più di un'etichetta? Quanti non ne hanno nessuna? La distribuzione delle etichette ha subito presentato un problema cioè il grande sbilanciamento tra le label. Inoltre nel nostro data set il 90% dei commenti non è tossico. Anche l'analisi delle distribuzioni delle multi label ha mostrato un grande sbilanciamento. Ho arricchito questa prima analisi con anche un grafico a barre normalizzate e una heatmap per meglio visualizzare le correlazioni. È stata anche studiata sia la distribuzione della lunghezza dei commenti che quella in funzione delle etichette. Le problematiche evidenziate dovranno poi essere trattate in fase di preprocessing dei dati.
2. Pulizia del testo, tokenizzazione e splitting: durante il preprocessing non ho svolto il bilanciamento del data set per avere un modello base di riferimento. Per preparare il testo ho definito due funzioni clean_text () e prepare_sequences(). La prima aveva il compito di rimuovere dal testo: indirizzi mail, URL, ridurre le lettere ripetute, rimuovere la punteggiatura, lemmizzare le parole, rimuovere le stopwords, eliminare numeri, caratteri non alfabetici e spazi multipli. La seconda invece doveva trasformare il testo in sequenze ed eseguire il padding oltre che il troncamento delle sequenze al 95 percentile della massima lunghezza. Per lo splitting ho usato il multilabel stratified e ho diviso il data set in train, test e val. Per la tokenizzazione ho scelto un vocab-size Di 20000.
3. Costruzione Di 4 modelli LSTM: L’architettura del modello che ho creato è stata la seguente: un layer di embedding, una LSTM, dropout, layer denso (funzione di attivazione relu), dropout e un altro layer denso con numero di nodi pari al numero di etichette (con funzione di attivazione sigmoide). L’utilizzo della sigmoide nell’ultimo layer è motivato dal fatto che stiamo analizzando un problema multilabel. I 4 modelli hanno avuto tutti questa struttura, le variazioni rispetto al primo sono state: nel secondo il bilanciamento delle classi, nel terzo l’architettura è stata un po’ modificato cambiando la LSTM con una LSTM bidirezionale e inserendo un layer di Global Max Pooling 1 dimensionale, nell’ultimo modello è stata aumentata la percentuale di dropout per diminuire l’overfitting. Le metriche su cui sono stati valutati i modelli sono state la subset accuracy, la micro F1-score e la precisione globale, con un occhio di riguardo nel non penalizzare eccessivamente le classi minoritarie. Purtroppo per la classe “minaccia” nonostante il bilanciamento, i sample disponibili erano troppo limitati perché il modello riuscisse a coglierne le caratteristiche. Per le altre etichette, Invece, ho ottenuto dei risultati soddisfacenti.
